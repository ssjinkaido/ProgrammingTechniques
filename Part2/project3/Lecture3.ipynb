{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: tests\n",
    "\n",
    "This lecture is based onto [https://realpython.com/python-testing/](https://realpython.com/python-testing/). \n",
    "Honestly, *realpython* is a very valuable source of documentation about Python, and reading their pages always a pleasure.\n",
    "\n",
    "As its title indicates it, this lecture is about testing in Python. Testing what? No, covid is old story, we want here to test Python code. &#x1F609;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Your Code\n",
    "There are many ways to test your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated vs. Manual Testing\n",
    "The good news is, you’ve probably already created a test without realizing it. Remember when you ran your application and used it for the first time? Did you check the features and experiment using them? That’s known as **exploratory testing** and is a form of manual testing.\n",
    "\n",
    "Exploratory testing is a form of testing that is done without a plan. In an exploratory test, you’re just exploring the application...\n",
    "\n",
    "To have a complete set of manual tests, all you need to do is make a list of all the features your application has, the different types of input it can accept, and the expected results. Now, every time you make a change to your code, you need to go through every single item on that list and check it like any airplane pilot does before to take off.\n",
    "\n",
    "That doesn’t sound like much fun, does it?\n",
    "\n",
    "This is where **automated testing** comes in. Automated testing is the execution of your test plan (the parts of your application you want to test, the order in which you want to test them, and the expected responses) by a script instead of a human. Python already comes with a set of tools and libraries to help you create automated tests for your application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Tests vs. Integration Tests\n",
    "\n",
    "The world of testing has no shortage of terminology, and now that you know the difference between automated and manual testing, it’s time to go a level deeper.\n",
    "\n",
    "Think of how you might test the lights on a car. You would turn on the lights (known as the test step) and go outside the car or ask a friend to check that the lights are on (known as the test assertion). **Testing multiple components at once is known as integration testing**.\n",
    "\n",
    "Think of all the things that need to work correctly in order for a simple task to give the right result. These components are like the parts to your application, all of those classes, functions, and modules you’ve written.\n",
    "\n",
    "*A major challenge with integration testing is when an integration test doesn’t give the right result*. It’s very hard to diagnose the issue without being able to isolate which part of the system is failing. If the lights didn’t turn on, then maybe the bulbs are broken. Is the battery dead? What about the alternator? Is the car’s computer failing?\n",
    "\n",
    "If you have a fancy modern car, it will tell you when your light bulbs have gone. It does this using a form of unit test. &#x1F60F;\n",
    "\n",
    "**A unit test is a smaller test**, one that checks that a single component operates in the right way. A unit test helps you to isolate what is broken in your application and fix it faster.\n",
    "\n",
    "You have just seen two types of tests:\n",
    "1. An integration test checks that components in your application operate with each other.\n",
    "2. A unit test checks a small component in your application.\n",
    "\n",
    "You can write both integration tests and unit tests in Python. To write a unit test for the built-in function `sum()`, you would check the output of `sum()` against a known output.\n",
    "\n",
    "For example, here’s how you check that the `sum()` of the numbers `(1, 2, 3)` equals `6`:\n",
    "```python\n",
    ">>> assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "```\n",
    "This will not output anything on the REPL because the values are correct.\n",
    "\n",
    "If the result from `sum()` is incorrect, this will fail with an `AssertionError` and the message `\"Should be 6\"`. Try an assertion statement again with the wrong values to see an AssertionError:\n",
    "```python\n",
    ">>> assert sum([1, 1, 1]) == 6, \"Should be 6\"\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "AssertionError: Should be 6\n",
    "```\n",
    "In the REPL, you are seeing the raised `AssertionError` because the result of `sum()` does not match `6`.\n",
    "\n",
    "Instead of testing on the REPL, you’ll want to put this into a new Python file called `test_sum.py` and execute it again:\n",
    "```python\n",
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sum()\n",
    "    print(\"Everything passed\")\n",
    "```\n",
    "Now you have written a test case, an assertion, and an entry point (the command line). You can now execute this at the command line:\n",
    "```bash\n",
    "$ python test_sum.py\n",
    "Everything passed\n",
    "```\n",
    "You can see the successful result, `Everything passed`.\n",
    "\n",
    "In Python, `sum()` accepts any iterable as its first argument. You tested with a list. Now test with a tuple as well. Create a new file called `test_sum_2.py` with the following code:\n",
    "```python\n",
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "def test_sum_tuple():\n",
    "    assert sum((1, 2, 2)) == 6, \"Should be 6\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sum()\n",
    "    test_sum_tuple()\n",
    "    print(\"Everything passed\")\n",
    "```\n",
    "When you execute `test_sum_2.py`, the script will give an error because the `sum()` of `(1, 2, 2)` is `5`, not `6`. The result of the script gives you the error message, the line of code, and the traceback:\n",
    "```bash\n",
    "$ python test_sum_2.py\n",
    "Traceback (most recent call last):\n",
    "  File \"test_sum_2.py\", line 9, in <module>\n",
    "    test_sum_tuple()\n",
    "  File \"test_sum_2.py\", line 5, in test_sum_tuple\n",
    "    assert sum((1, 2, 2)) == 6, \"Should be 6\"\n",
    "AssertionError: Should be 6\n",
    "```\n",
    "Here you can see how a mistake in your code gives an error on the console with some information on where the error was and what the expected result was.\n",
    "\n",
    "Writing tests in this way is okay for a simple check, but what if more than one fails? This is where **test runners** come in. The test runner is a special application designed for running tests, checking the output, and giving you tools for debugging and diagnosing tests and applications.\n",
    "\n",
    "There are different test runners in Python. In this lecture we are used the basic one: `unittest`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Testing with `unittest`\n",
    "`unittest` has been built into the Python standard library since version 2.1. \n",
    "You will probably see it in commercial Python applications and open-source projects.\n",
    "\n",
    "`unittest` contains both a testing framework and a test runner. \n",
    "It has some important requirements for writing and executing tests.\n",
    "\n",
    "It requires that:\n",
    "- You put your tests into classes as methods.\n",
    "- You use a series of special assertion methods in the `unittest.TestCase` class instead of the built-in `assert` statement.\n",
    "\n",
    "To convert the earlier example to a `unittest` test case, you would have to:\n",
    "- Import `unittest` from the standard library.\n",
    "- Create a class called `TestSum` that inherits from the `TestCase` class.\n",
    "- Convert the `test` functions into methods by adding `self` as the first argument.\n",
    "- Change the assertions to use the `self.assertEqual()` method on the `TestCase` class.\n",
    "- Change the command-line entry point to call `unittest.main()`.\n",
    "\n",
    "Follow those steps by creating a new file `test_sum_unittest.py` with the code provided in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_sum_unittest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_sum_unittest.py\n",
    "import unittest\n",
    "\n",
    "class TestSum(unittest.TestCase):\n",
    "    def test_sum(self):\n",
    "        self.assertEqual(sum([1, 2, 3]), 6, \"Should be 6\")\n",
    "\n",
    "    def test_sum_tuple(self):\n",
    "        self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute this in Python (use the next cell for this), you see one success (indicated with `.`) and one failure (indicated with `F`)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".F\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (__main__.TestSum)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"test_sum_unittest.py\", line 8, in test_sum_tuple\n",
      "    self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python test_sum_unittest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may add `-v` onto the command line to have a more complete output, as an option of the `unittest` module: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sum (test_sum_unittest.TestSum) ... ok\n",
      "test_sum_tuple (test_sum_unittest.TestSum) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (test_sum_unittest.TestSum)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuocmatcuamua/Desktop/MASTERUSTH/MI1.03/Part2/project3/test_sum_unittest.py\", line 8, in test_sum_tuple\n",
      "    self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest -v test_sum_unittest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done: You have just executed two tests using the `unittest` test runner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your First Test\n",
    "Let’s bring together what you’ve learned so far and, instead of testing the built-in `sum()` function, test a simple implementation of the same requirement.\n",
    "\n",
    "For this purpose we would like to create a **Python module**:\n",
    "- Create a new project folder called my_sum. \n",
    "- Inside my_sum, create an empty file called __init__.py. \n",
    "\n",
    "This is done by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import os\n",
    "dir = './my_sum'\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "    file = '__init__.py'\n",
    "    if not os.path.exists(dir + '/' + file):\n",
    "        with open(os.path.join(dir, file), 'w') as fp:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the `__init__.py` file means that the `my_sum` folder can be imported as a module from the parent directory.\n",
    "Then, we can add some functions and classes into this module, like it is done by running the next Python cell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_sum/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_sum/__init__.py\n",
    "def sum(arg):\n",
    "    total = 0\n",
    "    for val in arg:\n",
    "        total += val\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code example creates a variable called total, iterates over all the values in arg, and adds them to total. It then returns the result once the iterable has been exhausted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to Write the Test\n",
    "To get started writing tests, you can simply create a file called `test.py`, which will contain your first test case. Because the file will need to be able to import your application before to test it, you want to place `test.py` above the package folder, for us in the current directory.\n",
    "\n",
    "You’ll find that, as you add more and more tests, your single file will become cluttered and hard to maintain, so you can create a folder called `tests/` and split the tests into multiple files. \n",
    "It is convention to ensure each file starts with `test_` so all test runners will assume that Python file contains tests to be executed. \n",
    "Some very large projects split tests into more subdirectories based on their purpose or usage.\n",
    "\n",
    "Run the next cell to build the directory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import os\n",
    "dir = './tests'\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Structure a Simple Test\n",
    "Before you dive into writing tests, you’ll want to first make a couple of decisions:\n",
    "- What do you want to test?\n",
    "- Are you writing a unit test or an integration test?\n",
    "\n",
    "Then the structure of a test should loosely follow this workflow:\n",
    "- Create your inputs.\n",
    "- Execute the code being tested, capturing the output.\n",
    "- Compare the output with an expected result.\n",
    "\n",
    "For this application, you’re testing `sum()`. There are many behaviors in `sum()` you could check, such as:\n",
    "- Can it sum a list of whole numbers (integers)?\n",
    "- Can it sum a tuple or set?\n",
    "- Can it sum a list of floats?\n",
    "- What happens when you provide it with a bad value, such as a single integer or a string?\n",
    "- What happens when one of the values is negative?\n",
    "\n",
    "The most simple test would be a list of integers. This is done in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tests/test_sum.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tests/test_sum.py\n",
    "import unittest\n",
    "\n",
    "from my_sum import sum\n",
    "\n",
    "class TestSum(unittest.TestCase):\n",
    "    def test_list_int(self):\n",
    "        \"\"\"\n",
    "        Test that it can sum a list of integers\n",
    "        \"\"\"\n",
    "        data = [1, 2, 3]\n",
    "        result = sum(data)\n",
    "        self.assertEqual(result, 6)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Write Assertions\n",
    "\n",
    "The last step of writing a test is to validate the output against a known response. This is known as an assertion. There are some general best practices around how to **write assertions**:\n",
    "- Make sure tests are repeatable and run your test multiple times to make sure it gives the same result every time.\n",
    "- Try and assert results that relate to your input data, such as checking that the result is the actual sum of values in the `sum()` example.\n",
    "\n",
    "`unittest` comes with lots of methods to assert on the values, types, and existence of variables. \n",
    "Here are some of the most commonly used methods:\n",
    "| Method | Equivalent to |\n",
    "| :- | :- |\n",
    "| `.assertEqual(a, b)` | `a == b` |\n",
    "| `.assertTrue(x)` | `bool(x) is True` |\n",
    "| `.assertFalse(x)` | `bool(x) is False` |\n",
    "| `.assertIs(a, b)` | `a is b` |\n",
    "| `.assertIsNone(x)` | `x is None` |\n",
    "| `.assertIn(a, b)` | `a in b` |\n",
    "| `.assertIsInstance(a, b)` | `isinstance(a, b)` |\n",
    "\n",
    "`.assertIs()`, `.assertIsNone()`, `.assertIn()`, and `.assertIsInstance()` all have opposite methods, named `.assertIsNot()`, and so forth.\n",
    "\n",
    "### Side Effects\n",
    "When you’re writing tests, it’s often not as simple as looking at the return value of a function. \n",
    "Often, executing a piece of code will alter other things in the environment, such as the attribute of a class, a file on the filesystem, or a value in a database. \n",
    "These are known as **side effects** and are an important part of testing. \n",
    "Decide if the side effect is being tested before including it in your list of assertions.\n",
    "\n",
    "*Note: notice that this generally means a big problem in your application architecture, as the next lecture will try to explain it*. \n",
    "\n",
    "If you find that the unit of code you want to test has lots of side effects, you might be breaking the **Single Responsibility Principle**. Breaking the Single Responsibility Principle means the piece of code is doing too many things and would be better off being refactored. Following the Single Responsibility Principle is a great way to design code that it is easy to write repeatable and simple unit tests for, and ultimately, reliable applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the tests    \n",
    "\n",
    "### Executing Test Runners\n",
    "Now, let us try to run this test. Actually, there are different ways to do that. \n",
    "Here we just present three of them:\n",
    "1. By running it as Python script with `python tests/test_sum.py`.\n",
    "2. By running it as a module with `python -m unittest tests/test_sum.py`.\n",
    "3. By discovering and running all tests in a given directory with the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest discover -s tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Test Output\n",
    "\n",
    "That was a very simple example where everything passes, so now you’re going to try a failing test and interpret the output.\n",
    "\n",
    "`sum()` should be able to accept other lists of numeric types, like fractions.\n",
    "\n",
    "At the top of the `test_sum.py` file, we add an import statement to import the `Fraction` type from the `fractions` module in the standard library:\n",
    "```python\n",
    "from fractions import Fraction\n",
    "```\n",
    "Now we can add a test with an assertion expecting the **incorrect value**, in this case expecting the sum of `1/4`, `1/4`, and `2/5` to be 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/test_sum.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tests/test_sum.py\n",
    "import unittest\n",
    "\n",
    "from fractions import Fraction\n",
    "from my_sum import sum\n",
    "\n",
    "\n",
    "class TestSum(unittest.TestCase):\n",
    "    def test_list_int(self):\n",
    "        \"\"\"\n",
    "        Test that it can sum a list of integers\n",
    "        \"\"\"\n",
    "        data = [1, 2, 3]\n",
    "        result = sum(data)\n",
    "        self.assertEqual(result, 6)\n",
    "\n",
    "    def test_list_fraction(self):\n",
    "        \"\"\"\n",
    "        Test that it can sum a list of fractions\n",
    "        \"\"\"\n",
    "        data = [Fraction(1, 4), Fraction(1, 4), Fraction(2, 5)]\n",
    "        result = sum(data)\n",
    "        self.assertEqual(result, 1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.\n",
      "======================================================================\n",
      "FAIL: test_list_fraction (test_sum.TestSum)\n",
      "Test that it can sum a list of fractions\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuocmatcuamua/Desktop/MASTERUSTH/MI1.03/Part2/project3/tests/test_sum.py\", line 22, in test_list_fraction\n",
      "    self.assertEqual(result, 1)\n",
      "AssertionError: Fraction(9, 10) != 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest discover -s tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, you can see the following information:\n",
    "1. The first line shows the execution results of all the tests, `F.`: one failed (`F`) and one passed (`.`).\n",
    "2. The `FAIL` entry shows some details about the failed test:\n",
    "    - The test method name (`test_list_fraction`).\n",
    "    - The test module (`test_sum`) and the test case (`TestSum`).\n",
    "    - A `traceback` to the failing line.\n",
    "    - The details of the assertion with the expected result (`1`) and the actual result (`Fraction(9, 10)`).\n",
    "\n",
    "Again, we may add extra information to the test output by adding the `-v` flag to the `unittest` module as in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_list_fraction (test_sum.TestSum)\n",
      "Test that it can sum a list of fractions ... FAIL\n",
      "test_list_int (test_sum.TestSum)\n",
      "Test that it can sum a list of integers ... ok\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_list_fraction (test_sum.TestSum)\n",
      "Test that it can sum a list of fractions\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuocmatcuamua/Desktop/MASTERUSTH/MI1.03/Part2/project3/tests/test_sum.py\", line 22, in test_list_fraction\n",
      "    self.assertEqual(result, 1)\n",
      "AssertionError: Fraction(9, 10) != 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest discover -s tests -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced Testing Scenarios\n",
    "Before you step into creating tests for your application, remember the three basic steps of every test:\n",
    "- Create your inputs.\n",
    "- Execute the code, capturing the output.\n",
    "- Compare the output with an expected result.\n",
    "\n",
    "It is not always as easy as creating a static value for the input like a `string` or a `number`. \n",
    "Sometimes, your application will require an instance of a class or a context. \n",
    "What do you do then?\n",
    "\n",
    "The data that you create as an input is known as **a fixture**. \n",
    "It’s common practice to create fixtures and reuse them.\n",
    "\n",
    "If you are running the same test and passing different values each time and expecting the same result, this is known **as parameterization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Expected Failures\n",
    "Earlier, when you made a list of scenarios to test `sum()`, a question came up: \n",
    "What happens when you provide it with a bad value, such as a single integer or a string?\n",
    "\n",
    "In this case, you would expect `sum()` to throw an error. \n",
    "When it does throw an error, that would cause the test to fail.\n",
    "\n",
    "There is a special way to *handle expected errors*. \n",
    "You can use `.assertRaises()` as a context-manager, then inside the with block execute the test steps:\n",
    "```python\n",
    "class TestSum(unittest.TestCase):\n",
    "    ...\n",
    "    def test_bad_type(self):\n",
    "        data = \"banana\"\n",
    "        with self.assertRaises(TypeError):\n",
    "            result = sum(data)\n",
    "\n",
    "```\n",
    "This test case will now only pass if `sum(data)` raises a `TypeError`. \n",
    "You can replace `TypeError` with any exception type you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating Behaviors in Your Application\n",
    "Earlier in the lecture, you learned what a side effect is. \n",
    "Side effects make unit testing harder since, each time a test is run, it might give a different result, or even worse, one test could impact the state of the application and cause another test to fail!\n",
    "\n",
    "There are some simple techniques you can use to test parts of your application that have many side effects:\n",
    "- Refactoring code to follow the *Single Responsibility Principle*.\n",
    "- **Mocking** out any method or function calls to remove side effects.\n",
    "- Using *integration testing* instead of *unit testing* for this piece of the application.\n",
    "\n",
    "While Single Responsibility Principle is covered in the next lecture, and doing integration testing is not really a solution (because we still need to implement the unit tests!), let us take a look at the mocking solution comming with the `unittest` module.\n",
    "\n",
    "### Using `unittest.mocking`\n",
    "This section is based onto [https://docs.python.org/3/library/unittest.mock.html](https://docs.python.org/3/library/unittest.mock.html).\n",
    "\n",
    "`unittest.mock` provides a core `Mock` class removing the need to create a host of stubs throughout your test suite. \n",
    "After performing an action, you can make assertions about which methods / attributes were used and arguments they were called with. \n",
    "You can also specify return values and set needed attributes in the normal way.\n",
    "\n",
    "Additionally, `mock` provides a `patch()` *decorator* that handles patching module and class level attributes within the scope of a test, along with sentinel for creating unique objects. \n",
    "\n",
    "`Mock` is based on the ‘`action -> assertion`’ pattern instead of ‘`record -> replay`’ used by many mocking frameworks.\n",
    "\n",
    "`Mock` and `MagicMock` objects create all attributes and methods as you access them and store details of how they have been used. You can configure them, to specify return values or limit what attributes are available, and then make assertions about how they have been used:\n",
    "```python\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "thing = ProductionClass()\n",
    "thing.method = MagicMock(return_value=3)\n",
    "thing.method(3, 4, 5, key='value')\n",
    "thing.method.assert_called_with(3, 4, 5, key='value')\n",
    "```\n",
    "This example will produce a single line output:\n",
    "```bash\n",
    "3\n",
    "```\n",
    "`side_effect` allows you to perform side effects, including raising an exception when a mock is called:\n",
    "```python\n",
    "mock = Mock(side_effect=KeyError('foo'))\n",
    "mock()\n",
    "```\n",
    "It produces:\n",
    "```bash\n",
    "Traceback (most recent call last):\n",
    " ...\n",
    "KeyError: 'foo'\n",
    "```\n",
    "Another `side_effect` example is at follows:\n",
    "```python\n",
    "def side_effect(arg):\n",
    "    values = {'a': 1, 'b': 2, 'c': 3}\n",
    "    return values[arg]\n",
    "\n",
    "mock.side_effect = side_effect\n",
    "mock('a'), mock('b'), mock('c')\n",
    "\n",
    "mock.side_effect = [5, 4, 3, 2, 1]\n",
    "mock(), mock(), mock()\n",
    "```\n",
    "It produces as output:\n",
    "```bash\n",
    "(1, 2, 3)\n",
    "(5, 4, 3)\n",
    "```\n",
    "`Mock` has many other ways you can configure it and control its behaviour. \n",
    "For example the `spec` argument configures the mock to take its specification from another object. \n",
    "Attempting to access attributes or methods on the mock that don’t exist on the `spec` will fail with an `AttributeError`.\n",
    "\n",
    "The `patch()` decorator / context manager makes it easy to mock classes or objects in a module under test. \n",
    "The object you specify will be replaced with a `mock` (or other object) during the test and restored when the test ends:\n",
    "```python\n",
    "from unittest.mock import patch\n",
    "\n",
    "@patch('module.ClassName2')\n",
    "@patch('module.ClassName1')\n",
    "def test(MockClass1, MockClass2):\n",
    "    module.ClassName1()\n",
    "    module.ClassName2()\n",
    "    assert MockClass1 is module.ClassName1\n",
    "    assert MockClass2 is module.ClassName2\n",
    "    assert MockClass1.called\n",
    "    assert MockClass2.called\n",
    "\n",
    "test()\n",
    "```\n",
    "Notice the patch decorator order: \n",
    "When you nest patch decorators the mocks are passed in to the decorated function in the same order they applied (the normal Python order that decorators are applied). This means from the bottom up, so in the example above the mock for `module.ClassName1` is passed in first.\n",
    "\n",
    "With `patch()` it matters that you patch objects in the namespace where they are looked up. \n",
    "This is normally straightforward, but for a quick guide read where to patch.\n",
    "\n",
    "As well as a decorator `patch()` can be used as a context manager in a with statement:\n",
    "```python\n",
    "with patch.object(ProductionClass, 'method', return_value=None) as mock_method:\n",
    "    thing = ProductionClass()\n",
    "    thing.method(1, 2, 3)\n",
    "\n",
    "mock_method.assert_called_once_with(1, 2, 3)\n",
    "```\n",
    "There is also `patch.dict()` for setting values in a dictionary just during a scope and restoring the dictionary to its original state when the test ends:\n",
    "```python\n",
    "foo = {'key': 'value'}\n",
    "original = foo.copy()\n",
    "with patch.dict(foo, {'newkey': 'newvalue'}, clear=True):\n",
    "    assert foo == {'newkey': 'newvalue'}\n",
    "\n",
    "assert foo == original\n",
    "```\n",
    "Mock supports the mocking of Python magic methods. \n",
    "The easiest way of using magic methods is with the `MagicMock` class. \n",
    "It allows you to do things like:\n",
    "```python\n",
    "mock = MagicMock()\n",
    "mock.__str__.return_value = 'foobarbaz'\n",
    "str(mock)\n",
    "mock.__str__.assert_called_with()\n",
    "```\n",
    "that produces a single output:\n",
    "```bash\n",
    "'foobarbaz'\n",
    "```\n",
    "Notice that the assertion is not raised, since the method was called just before...\n",
    "\n",
    "Mock allows you to assign functions (or other Mock instances) to magic methods and they will be called appropriately. \n",
    "The MagicMock class is just a Mock variant that has all of the magic methods pre-created for you (well, all the useful ones anyway).\n",
    "\n",
    "The following is an example of using magic methods with the ordinary Mock class:\n",
    "```python\n",
    "mock = Mock()\n",
    "mock.__str__ = Mock(return_value='wheeeeee')\n",
    "str(mock)\n",
    "```\n",
    "that produces as output:\n",
    "```bash\n",
    "'wheeeeee'\n",
    "```\n",
    "\n",
    "For ensuring that the `mock` objects in your tests have the same api as the objects they are replacing, you can use auto-speccing. \n",
    "Auto-speccing can be done through the `autospec` argument to `patch`, or the `create_autospec()` function. Auto-speccing creates mock objects that have the same attributes and methods as the objects they are replacing, and any functions and methods (including constructors) have the same call signature as the real object.\n",
    "\n",
    "This ensures that your mocks will fail in the same way as your production code if they are used incorrectly:\n",
    "```python\n",
    "from unittest.mock import create_autospec\n",
    "\n",
    "def function(a, b, c):\n",
    "    pass\n",
    "\n",
    "mock_function = create_autospec(function, return_value='fishy')\n",
    "mock_function(1, 2, 3)\n",
    "mock_function.assert_called_once_with(1, 2, 3)\n",
    "mock_function('wrong arguments')\n",
    "```\n",
    "that will produces the following two outputs:\n",
    "```bash\n",
    "'fishy'\n",
    "Traceback (most recent call last):\n",
    " ...\n",
    "TypeError: <lambda>() takes exactly 3 arguments (1 given)\n",
    "```\n",
    "`create_autospec()` can also be used on classes, where it copies the signature of the `__init__` method, and on callable objects where it copies the signature of the `__call__` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "This lecture just gave you a short overview of the testing problem and the Python tools to accomplish it. \n",
    "It have not covered the integration testing, the data driven testing, the continuous integration (e.g. using Travis CI on GitLab/GitHub), in-depth mocking, code coverage problem, full functional testing, multiple os testing, and so on. \n",
    "\n",
    "That's a good news: you still have so many things to discover &#x1F609;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('allenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fb21341b2262334c6746f00bb237b214a3c5c5b906cfe81d5af4498149236dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
